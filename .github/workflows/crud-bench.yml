name: Performance Benchmarks
#
# This workflow runs CRUD benchmarks using a pinned version of crud-bench.
# The crud-bench revision is intentionally pinned to ensure consistent
# benchmarking across all PRs (apples-to-apples comparison).
#
# Documentation: doc/BENCHMARKING.md
#
# To upgrade crud-bench:
# 1. Update the CRUD_BENCH_REVISION in the env section below
# 2. Test manually using workflow_dispatch with the new revision
# 3. Commit and let benchmarks run on a PR to verify

run-name: "Benchmark run '${{ github.head_ref || github.ref_name }}'"

on:
  workflow_dispatch:
    inputs:
      crud_bench_revision:
        description: 'crud-bench git revision (commit, tag, or branch)'
        required: false
        type: string
  pull_request:
    types:
      - opened
      - synchronize
      - reopened

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

permissions:
  pull-requests: write

env:
  # Default crud-bench revision - update this to upgrade crud-bench version
  # This ensures consistent benchmarking across all PRs
  CRUD_BENCH_REVISION: ${{ inputs.crud_bench_revision || '8accc013fe279b458d1378f41ba9a9b5ea4ffee2' }}

jobs:
  # ----------------------------------------
  # Build SurrealDB binaries with minimal features
  # ----------------------------------------

  build-surrealdb-binaries:
    name: Build SurrealDB (${{ matrix.config }})
    runs-on: [self-hosted, benchmarking]
    timeout-minutes: 15
    strategy:
      fail-fast: false
      matrix:
        config:
          - memory
          - rocksdb
    
    steps:
      - name: Checkout sources
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      
      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          save-cache: false
      
      - name: Build SurrealDB with minimal features
        run: |
          # Determine features based on configuration
          case "${{ matrix.config }}" in
            memory)
              FEATURES="storage-mem,http"
              echo "Building SurrealDB with in-memory storage only"
              ;;
            rocksdb)
              FEATURES="storage-rocksdb,http"
              echo "Building SurrealDB with RocksDB storage only"
              ;;
            *)
              echo "Unknown config: ${{ matrix.config }}"
              exit 1
              ;;
          esac
          
          echo "Features: $FEATURES"
          cargo build --release --no-default-features --features "$FEATURES"
      
      - name: Upload binary
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: surreal-binary-${{ matrix.config }}
          path: target/release/surreal
          retention-days: 1

  # ----------------------------------------
  # Build crud-bench with patched surrealdb
  # ----------------------------------------

  build-crud-bench:
    name: Build crud-bench
    runs-on: [self-hosted, benchmarking]
    timeout-minutes: 15
    
    steps:
      - name: Checkout sources
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      
      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          save-cache: false
      
      - name: Checkout crud-bench repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: surrealdb/crud-bench
          ref: ${{ env.CRUD_BENCH_REVISION }}
          path: .github/tools/crud-bench
      
      - name: Setup crud-bench cache
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2.8.2
        with:
          workspaces: .github/tools/crud-bench
          cache-on-failure: true
          save-if: ${{ github.ref == 'refs/heads/main' }}
      
      - name: Align SurrealDB version with crud-bench
        run: |
          # Extract the surrealdb version that crud-bench expects
          EXPECTED_VERSION=$(grep -A 2 '[[package]]' .github/tools/crud-bench/Cargo.lock | grep -A 1 'name = "surrealdb"' | grep 'version = ' | head -1 | cut -d '"' -f 2)
          echo "crud-bench expects surrealdb version: $EXPECTED_VERSION"

          # Get current version
          CURRENT_VERSION=$(grep '^version = ' Cargo.toml | head -1 | cut -d '"' -f 2)
          echo "Current workspace version: $CURRENT_VERSION"

          if [ "$EXPECTED_VERSION" != "$CURRENT_VERSION" ]; then
            echo "Updating workspace and internal crate versions to $EXPECTED_VERSION"

            # Update workspace package version
            sed -i "s/^version = \"$CURRENT_VERSION\"/version = \"$EXPECTED_VERSION\"/" Cargo.toml

            # Update all internal surrealdb-* dependency versions in workspace.dependencies
            sed -i "s/surrealdb\([a-z-]*\) = { version = \"$CURRENT_VERSION\"/surrealdb\1 = { version = \"$EXPECTED_VERSION\"/g" Cargo.toml

            echo "Updated Cargo.toml workspace and dependency versions"
          else
            echo "Versions already match, no changes needed"
          fi
      
      - name: Build crud-bench
        run: |
          cd .github/tools/crud-bench
          
          # Update only surrealdb and its dependencies to resolve conflicts with the patched version
          # This keeps all other crud-bench dependencies locked for consistent benchmarking
          cargo update -p surrealdb
          
          # Build with only the database features we actually use
          cargo build --release --no-default-features --features "surrealdb,surrealkv,surrealmx"
      
      - name: Upload binary
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: crud-bench-binary
          path: .github/tools/crud-bench/target/release/crud-bench
          retention-days: 1

  # ----------------------------------------
  # Run CRUD benchmarks
  # ----------------------------------------

  benchmark:
    name: CRUD Benchmark (${{ matrix.config }}-${{ matrix.key_type }})
    runs-on: [self-hosted, benchmarking]
    needs: [build-surrealdb-binaries, build-crud-bench]
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        # Cartesian product: config √ó key_type
        config:
          - memory
          - rocksdb
          - embedded-memory
          - embedded-rocksdb
          - surrealkv-local
          - surrealmx
        key_type:
          - integer
          - string26
          - string90
          - string250
        
        # Add metadata for each config
        include:
          # Networked configurations
          - config: memory
            database: surrealdb-memory
            endpoint: ws://localhost:8000
            needs_server: true
            description: SurrealDB with in-memory storage
            display_name: Memory (Networked)

          - config: rocksdb
            database: surrealdb-rocksdb
            endpoint: ws://localhost:8000
            needs_server: true
            description: SurrealDB with RocksDB storage
            display_name: RocksDB (Networked)

          # Embedded configurations
          - config: embedded-memory
            database: surrealdb
            endpoint: memory
            needs_server: false
            description: SurrealDB embedded with in-memory storage
            display_name: Embedded Memory

          - config: embedded-rocksdb
            database: surrealdb
            endpoint: rocksdb:~/crud-bench-data
            needs_server: false
            description: SurrealDB embedded with RocksDB storage
            display_name: Embedded RocksDB

          # Other engines
          - config: surrealkv-local
            database: surrealkv
            needs_server: false
            description: SurrealKV storage engine
            display_name: SurrealKV

          - config: surrealmx
            database: surrealmx
            needs_server: false
            description: SurrealMX storage engine
            display_name: SurrealMX

    steps:
      - name: Checkout sources
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Determine configuration
        id: meta
        run: |
          # Configuration comes from matrix - just set result name
          echo "result_name=${{ matrix.config }}-${{ matrix.key_type }}" >> $GITHUB_OUTPUT

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          save-cache: false

      - name: Download SurrealDB binary (for networked benchmarks)
        if: matrix.needs_server == true
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          name: surreal-binary-${{ matrix.config }}
          path: ${{ github.workspace }}/bin
      
      - name: Make SurrealDB binary executable
        if: matrix.needs_server == true
        run: |
          chmod +x ${{ github.workspace }}/bin/surreal
          echo "${{ github.workspace }}/bin" >> $GITHUB_PATH
          echo "SurrealDB binary ready at: ${{ github.workspace }}/bin/surreal"
      
      - name: Checkout crud-bench repository (for directory structure)
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: surrealdb/crud-bench
          ref: ${{ env.CRUD_BENCH_REVISION }}
          path: .github/tools/crud-bench
      
      - name: Download crud-bench binary
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          name: crud-bench-binary
          path: .github/tools/crud-bench/target/release/
      
      - name: Make crud-bench binary executable
        run: |
          chmod +x .github/tools/crud-bench/target/release/crud-bench
          echo "crud-bench binary ready"

      - name: Prepare environment
        run: |
          # Create data directory for embedded benchmarks
          mkdir -p ~/crud-bench-data
          chmod 777 ~/crud-bench-data
          
          # Create data directory for networked benchmarks (if needed)
          if [ "${{ matrix.needs_server }}" = "true" ]; then
            mkdir -p ~/surrealdb-data
          fi
          
          # Clean up any existing result files
          rm -f result*.json result*.html result*.csv

      - name: Optimize system
        run: |
          sync
          ulimit -n 65536 || true
          ulimit -u unlimited || true
          ulimit -l unlimited || true

      - name: Print system information
        run: |
          echo "=== System Information ==="
          echo "Hostname: $(hostname)"
          echo "OS: $(uname -s)"
          echo "Kernel: $(uname -r)"
          echo "Architecture: $(uname -m)"
          echo "CPU Info:"
          if [ -f /proc/cpuinfo ]; then
            grep "model name" /proc/cpuinfo | head -1
            echo "CPU Cores: $(nproc)"
          elif command -v sysctl &> /dev/null; then
            sysctl -n machdep.cpu.brand_string
            echo "CPU Cores: $(sysctl -n hw.ncpu)"
          fi
          echo "Memory:"
          if command -v free &> /dev/null; then
            free -h
          elif command -v vm_stat &> /dev/null; then
            vm_stat | head -5
          fi

      - name: Start SurrealDB server (for networked benchmarks)
        if: matrix.needs_server == true
        run: |
          # Start SurrealDB in the background using the PR's binary
          case "${{ matrix.database }}" in
            surrealdb-memory)
              echo "Starting SurrealDB with in-memory storage..."
              surreal start --log error --user root --pass root memory &
              ;;
            surrealdb-rocksdb)
              echo "Starting SurrealDB with RocksDB storage..."
              surreal start --log error --user root --pass root rocksdb:~/surrealdb-data &
              ;;
            surrealdb-surrealkv)
              echo "Starting SurrealDB with SurrealKV storage..."
              surreal start --log error --user root --pass root surrealkv:~/surrealdb-data &
              ;;
          esac
          
          # Store the PID for cleanup
          echo $! > /tmp/surrealdb.pid
          echo "SurrealDB started with PID $(cat /tmp/surrealdb.pid)"
          
          # Wait for server to be ready
          echo "Waiting for SurrealDB to start..."
          for i in {1..30}; do
            if curl -s http://localhost:8000/health > /dev/null 2>&1; then
              echo "‚úì SurrealDB is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "‚úó SurrealDB failed to start"
              exit 1
            fi
            sleep 1
          done

      - name: Run benchmark - ${{ matrix.description }} (${{ matrix.key_type }})
        timeout-minutes: 10
        run: |
          cd .github/tools/crud-bench
          
          # Build benchmark command
          CMD="./target/release/crud-bench -d ${{ matrix.database }}"
          
          # Add endpoint if specified
          if [ -n "${{ matrix.endpoint }}" ]; then
            CMD="$CMD --endpoint ${{ matrix.endpoint }}"
          fi
          
          # Add benchmark parameters
          CMD="$CMD -s 10000 -c 12 -t 48 -r -k ${{ matrix.key_type }} -n ${{ steps.meta.outputs.result_name }}"
          
          # Store display name in a separate file for the analysis script
          echo "${{ matrix.display_name }}" > display_name_${{ steps.meta.outputs.result_name }}.txt
          
          echo "Running: $CMD"
          eval $CMD
        env:
          SURREALDB_USER: root
          SURREALDB_PASS: root

      - name: Collect results
        run: |
          mkdir -p ${{ github.workspace }}/benchmark-results
          cp .github/tools/crud-bench/result*.json ${{ github.workspace }}/benchmark-results/ || true
          cp .github/tools/crud-bench/display_name_*.txt ${{ github.workspace }}/benchmark-results/ || true
          ls -la ${{ github.workspace }}/benchmark-results

      - name: Upload benchmark results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: benchmark-results-${{ steps.meta.outputs.result_name }}
          path: ${{ github.workspace }}/benchmark-results/*
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          # Kill SurrealDB server if it was started
          if [ -f /tmp/surrealdb.pid ]; then
            echo "Stopping SurrealDB server..."
            PID=$(cat /tmp/surrealdb.pid)
            kill $PID 2>/dev/null || true
            # Wait for process to fully terminate
            for i in {1..10}; do
              if ! kill -0 $PID 2>/dev/null; then
                break
              fi
              sleep 0.5
            done
            rm -f /tmp/surrealdb.pid
          fi
          
          # Clean up data directories (with retry for file handle release)
          for dir in ~/surrealdb-data ~/crud-bench-data; do
            if [ -d "$dir" ]; then
              rm -rf "$dir" 2>/dev/null || {
                echo "Warning: Failed to remove $dir on first attempt, retrying..."
                sleep 1
                rm -rf "$dir" 2>/dev/null || echo "Warning: Could not fully clean $dir"
              }
            fi
          done

  # ----------------------------------------
  # Analyze results and report
  # ----------------------------------------

  analyze-and-report:
    name: Analyze and Report
    runs-on: ubuntu-latest
    needs: [benchmark]
    if: always()
    steps:
      - name: Checkout sources
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0

      - name: Download all benchmark results
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          pattern: benchmark-results-*
          path: ${{ github.workspace }}/results
          merge-multiple: true

      - name: List downloaded results
        run: |
          echo "Downloaded benchmark results:"
          find ${{ github.workspace }}/results -type f

      - name: Setup Python
        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0
        with:
          python-version: '3.11'

      - name: Run analysis
        id: analysis
        run: |
          python3 .github/scripts/analyze_benchmark.py \
            --results-dir ${{ github.workspace }}/results \
            --output ${{ github.workspace }}/report.md \
            --json-output ${{ github.workspace }}/analysis.json
        continue-on-error: true

      - name: Prepare PR comment
        if: github.event_name == 'pull_request'
        run: |
          if [ -f ${{ github.workspace }}/report.md ]; then
            # Append workflow link to the report
            echo "" >> ${{ github.workspace }}/report.md
            echo "---" >> ${{ github.workspace }}/report.md
            echo "<sub>Benchmark run: [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})</sub>" >> ${{ github.workspace }}/report.md
          else
            # Create a fallback report if analysis failed
            echo "## üîç CRUD Benchmark Results" > ${{ github.workspace }}/report.md
            echo "" >> ${{ github.workspace }}/report.md
            echo "‚ö†Ô∏è Benchmark analysis failed. Check the [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details." >> ${{ github.workspace }}/report.md
          fi

      - name: Find existing comment
        if: github.event_name == 'pull_request'
        uses: peter-evans/find-comment@3eae4d37986fb5a8592848f6a574fdf654e61f9e # v3.1.0
        id: find_comment
        with:
          issue-number: ${{ github.event.pull_request.number }}
          comment-author: 'github-actions[bot]'
          body-includes: '## üîç CRUD Benchmark Results'

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: peter-evans/create-or-update-comment@71345be0265236311c031f5c7866368bd1eff043 # v4.0.0
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body-path: ${{ github.workspace }}/report.md
          comment-id: ${{ steps.find_comment.outputs.comment-id }}
          edit-mode: replace

      - name: Upload analysis results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: benchmark-analysis
          path: |
            ${{ github.workspace }}/report.md
            ${{ github.workspace }}/analysis.json
          retention-days: 90
