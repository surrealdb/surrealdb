name: Performance Benchmarks
#
# This workflow runs CRUD benchmarks using a pinned version of crud-bench.
# The crud-bench revision is intentionally pinned to ensure consistent
# benchmarking across all PRs (apples-to-apples comparison).
#
# Documentation: doc/BENCHMARKING.md
#
# To upgrade crud-bench:
# 1. Update the CRUD_BENCH_REVISION in the env section below
# 2. Test manually using workflow_dispatch with the new revision
# 3. Commit and let benchmarks run on a PR to verify

run-name: "Benchmark run '${{ github.head_ref || github.ref_name }}'"

on:
  workflow_dispatch:
    inputs:
      crud_bench_revision:
        description: 'crud-bench git revision (commit, tag, or branch)'
        required: false
        type: string
  pull_request:
    types:
      - opened
      - synchronize
      - reopened

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

permissions:
  pull-requests: write

env:
  # Default crud-bench revision - update this to upgrade crud-bench version
  # This ensures consistent benchmarking across all PRs
  CRUD_BENCH_REVISION: ${{ inputs.crud_bench_revision || 'rushmore/embeddable' }}

jobs:
  # ----------------------------------------
  # Run CRUD benchmarks
  # ----------------------------------------

  crud-benchmark:
    name: CRUD Benchmark (${{ matrix.name }})
    runs-on: [runner-amd64-large]
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        include:
          # SurrealDB + Memory (WebSocket)
          - name: memory
            database: surrealdb-memory
            endpoint: ws://localhost:8000
            description: SurrealDB with in-memory storage
          # SurrealDB + RocksDB (WebSocket)
          - name: rocksdb
            database: surrealdb-rocksdb
            endpoint: ws://localhost:8000
            description: SurrealDB with RocksDB storage
          # SurrealDB + SurrealKV (WebSocket)
          - name: surrealkv
            database: surrealdb-surrealkv
            endpoint: ws://localhost:8000
            description: SurrealDB with SurrealKV storage
            skipped: SurrealDB with SurrealKV storage benchmark awaiting fixes
          # SurrealDB Memory Engine (Embedded)
          - name: embedded-memory
            database: surrealdb
            endpoint: memory
            description: SurrealDB embedded with in-memory storage
          # SurrealDB RocksDB Engine (Embedded)
          - name: embedded-rocksdb
            database: surrealdb
            endpoint: rocksdb:~/crud-bench
            description: SurrealDB embedded with RocksDB storage
          # SurrealDB SurrealKV Engine (Embedded)
          - name: embedded-surrealkv
            database: surrealdb
            endpoint: surrealkv:~/crud-bench
            description: SurrealDB embedded with SurrealKV storage
            skipped: SurrealDB with SurrealKV storage benchmark awaiting fixes
          # SurrealKV
          - name: surrealkv
            database: surrealkv
            description: SurrealKV
          # SurrealMX
          - name: surrealmx
            database: surrealmx
            description: SurrealMX

    steps:
      - name: Skip if matrix.skipped is set
        if: matrix.skipped
        run: |
          echo "‚è≠Ô∏è Skipping benchmark: ${{ matrix.skipped }}"
          exit 0

      - name: Checkout sources
        if: ${{ !matrix.skipped }}
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup environment
        if: ${{ !matrix.skipped }}
        uses: ./.github/actions/setup-environment
        with:
          save-cache: false

      - name: Build SurrealDB binary
        if: ${{ !matrix.skipped }}
        run: |
          cargo build
          mkdir -p ${{ github.workspace }}/bin
          cp target/debug/surreal ${{ github.workspace }}/bin/
          echo "${{ github.workspace }}/bin" >> $GITHUB_PATH

      - name: Checkout crud-bench repository
        if: ${{ !matrix.skipped }}
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: surrealdb/crud-bench
          ref: ${{ env.CRUD_BENCH_REVISION }}
          path: .github/tools/crud-bench

      - name: Setup crud-bench cache
        if: ${{ !matrix.skipped }}
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2.8.2
        with:
          workspaces: .github/tools/crud-bench
          cache-on-failure: true
          save-if: ${{ github.ref == 'refs/heads/main' }}

      - name: Align SurrealDB version with crud-bench
        if: ${{ !matrix.skipped }}
        run: |
          # Extract the surrealdb version that crud-bench expects
          EXPECTED_VERSION=$(grep -A 2 '[[package]]' .github/tools/crud-bench/Cargo.lock | grep -A 1 'name = "surrealdb"' | grep 'version = ' | head -1 | cut -d '"' -f 2)
          echo "crud-bench expects surrealdb version: $EXPECTED_VERSION"

          # Get current version
          CURRENT_VERSION=$(grep '^version = ' Cargo.toml | head -1 | cut -d '"' -f 2)
          echo "Current workspace version: $CURRENT_VERSION"

          if [ "$EXPECTED_VERSION" != "$CURRENT_VERSION" ]; then
            echo "Updating workspace and internal crate versions to $EXPECTED_VERSION"

            # Update workspace package version
            sed -i "s/^version = \"$CURRENT_VERSION\"/version = \"$EXPECTED_VERSION\"/" Cargo.toml

            # Update all internal surrealdb-* dependency versions in workspace.dependencies
            sed -i "s/surrealdb\([a-z-]*\) = { version = \"$CURRENT_VERSION\"/surrealdb\1 = { version = \"$EXPECTED_VERSION\"/g" Cargo.toml

            echo "Updated Cargo.toml workspace and dependency versions"
          else
            echo "Versions already match, no changes needed"
          fi

      - name: Build crud-bench
        if: ${{ !matrix.skipped }}
        run: |
          cd .github/tools/crud-bench
          cargo build

      - name: Setup Docker (if needed)
        if: ${{ !matrix.skipped }}
        run: |
          docker --version
          docker ps

      - name: Clean up environment
        if: ${{ !matrix.skipped }}
        run: |
          rm -rf ~/crud-bench-data
          mkdir -p ~/crud-bench-data
          chmod 777 ~/crud-bench-data
          rm -f result*.json result*.html result*.csv
          docker container prune --force || true
          docker volume prune --all --force || true

      - name: Optimize system
        if: ${{ !matrix.skipped }}
        run: |
          sync
          ulimit -n 65536 || true
          ulimit -u unlimited || true
          ulimit -l unlimited || true

      - name: Start local SurrealDB server (for networked benchmarks)
        if: ${{ !matrix.skipped && startsWith(matrix.database, 'surrealdb-') }}
        run: |
          mkdir -p ~/surrealdb-data

          # Start SurrealDB in the background using the PR's binary
          case "${{ matrix.database }}" in
            surrealdb-memory)
              echo "Starting SurrealDB with in-memory storage..."
              ;;
            surrealdb-rocksdb)
              echo "Starting SurrealDB with RocksDB storage..."
              ;;
            surrealdb-surrealkv)
              echo "Starting SurrealDB with SurrealKV storage..."
              ;;
          esac

          surreal start --log error --user root --pass root ${{ matrix.endpoint }} &

          # Store the PID for cleanup
          echo $! > /tmp/surrealdb.pid
          echo "SurrealDB started with PID $(cat /tmp/surrealdb.pid)"

          # Wait for server to be ready
          echo "Waiting for SurrealDB to start..."
          for i in {1..30}; do
            if curl -s http://localhost:8000/health > /dev/null 2>&1; then
              echo "‚úì SurrealDB is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "‚úó SurrealDB failed to start"
              exit 1
            fi
            sleep 1
          done

      - name: Run benchmark - ${{ matrix.description }}
        if: ${{ !matrix.skipped }}
        timeout-minutes: 30
        run: |
          cd .github/tools/crud-bench
          
          # Build the command with optional endpoint
          CMD="./target/debug/crud-bench -d ${{ matrix.database }}"
          
          if [ -n "${{ matrix.endpoint }}" ]; then
            CMD="$CMD --endpoint ${{ matrix.endpoint }}"
          fi
          
          CMD="$CMD -s 10000 -c 12 -t 48 -r -n ${{ matrix.name }}"
          
          # Execute the benchmark
          eval $CMD
        env:
          SURREALDB_USER: root
          SURREALDB_PASS: root

      - name: Collect results
        if: ${{ !matrix.skipped }}
        run: |
          mkdir -p ${{ github.workspace }}/benchmark-results
          cp .github/tools/crud-bench/result*.json ${{ github.workspace }}/benchmark-results/ || true
          ls -la ${{ github.workspace }}/benchmark-results

      - name: Upload benchmark results
        if: ${{ !matrix.skipped }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: benchmark-results-${{ matrix.name }}
          path: ${{ github.workspace }}/benchmark-results/*.json
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          # Kill local SurrealDB server if it was started
          if [ -f /tmp/surrealdb.pid ]; then
            echo "Stopping local SurrealDB server..."
            kill $(cat /tmp/surrealdb.pid) 2>/dev/null || true
            rm /tmp/surrealdb.pid
          fi

          # Docker cleanup
          docker container kill crud-bench &>/dev/null || true
          docker container rm crud-bench &>/dev/null || true
          docker container prune --force || true
          docker volume prune --all --force || true

  # ----------------------------------------
  # Analyze results and report
  # ----------------------------------------

  analyze-and-report:
    name: Analyze and Report
    runs-on: ubuntu-latest
    needs: [crud-benchmark]
    if: always()
    steps:
      - name: Checkout sources
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0

      - name: Download all benchmark results
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          pattern: benchmark-results-*
          path: ${{ github.workspace }}/results
          merge-multiple: true

      - name: List downloaded results
        run: |
          echo "Downloaded benchmark results:"
          find ${{ github.workspace }}/results -type f

      - name: Setup Python
        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0
        with:
          python-version: '3.11'

      - name: Run analysis
        id: analysis
        run: |
          python3 .github/scripts/analyze_benchmark.py \
            --results-dir ${{ github.workspace }}/results \
            --output ${{ github.workspace }}/report.md \
            --json-output ${{ github.workspace }}/analysis.json
        continue-on-error: true

      - name: Prepare PR comment
        if: github.event_name == 'pull_request'
        run: |
          if [ -f ${{ github.workspace }}/report.md ]; then
            # Append workflow link to the report
            echo "" >> ${{ github.workspace }}/report.md
            echo "---" >> ${{ github.workspace }}/report.md
            echo "<sub>Benchmark run: [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})</sub>" >> ${{ github.workspace }}/report.md
          else
            # Create a fallback report if analysis failed
            echo "## üîç CRUD Benchmark Results" > ${{ github.workspace }}/report.md
            echo "" >> ${{ github.workspace }}/report.md
            echo "‚ö†Ô∏è Benchmark analysis failed. Check the [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details." >> ${{ github.workspace }}/report.md
          fi

      - name: Find existing comment
        if: github.event_name == 'pull_request'
        uses: peter-evans/find-comment@3eae4d37986fb5a8592848f6a574fdf654e61f9e # v3.1.0
        id: find_comment
        with:
          issue-number: ${{ github.event.pull_request.number }}
          comment-author: 'github-actions[bot]'
          body-includes: '## üîç CRUD Benchmark Results'

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: peter-evans/create-or-update-comment@71345be0265236311c031f5c7866368bd1eff043 # v4.0.0
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body-path: ${{ github.workspace }}/report.md
          comment-id: ${{ steps.find_comment.outputs.comment-id }}
          edit-mode: replace

      - name: Upload analysis results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: benchmark-analysis
          path: |
            ${{ github.workspace }}/report.md
            ${{ github.workspace }}/analysis.json
          retention-days: 90
